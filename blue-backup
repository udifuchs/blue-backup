#! /usr/bin/env python3
"""Backup using rsync."""

from __future__ import annotations

import argparse
import dataclasses
import datetime
import enum
import getpass
import os
import pathlib
import stat
import subprocess
import sys
from collections.abc import Callable, Iterator
from typing import BinaryIO, Literal, Sequence, TypeAlias, TypedDict, cast

if sys.version_info >= (3, 11):
    import tomllib
else:
    import tomli as tomllib

import paramiko

OpenBinaryMode: TypeAlias = Literal["rb", "wb", "ab"]


class BlueError(Exception):
    """blue-backup failed."""


class Logger(enum.Enum):
    """Log messages."""

    OUTPUT = "\033[32m"  # Green
    COMMAND = "\033[94m"  # Blue
    ERROR = "\033[91m"  # Red
    WARNING = "\033[33m"  # Yellow
    _RESET = "\033[0m"

    def print(self, text: str) -> None:
        """Print a log message."""
        stream = sys.stderr if self in {Logger.ERROR, Logger.WARNING} else sys.stdout
        if stream.isatty():
            stream.write(f"{self.value}{text}{Logger._RESET.value}\n")
        else:
            stream.write(f"{text}\n")
            # Flushing is needed when invoked using: ssh hostname ./blue-backup
            # To get a colored output, force pseudo-terminal allocation using: ssh -t
            stream.flush()


class Process:
    """Handle local and remote processes and filesystem access.

    For local access, subprocess and pathlib modules are used.
    For remote access, paramiko's ssh and sftp are used.
    """

    def __init__(self, address: str | None) -> None:
        """Initialize process for remote or local host."""
        hostname: str | None
        if address is not None and "@" in address:
            username, hostname = address.split("@", 2)
        else:
            username, hostname = os.getlogin(), address
        self.address = address

        self.ssh = None
        self.sftp = None
        if hostname is not None:
            self.ssh = paramiko.SSHClient()
            self.ssh.load_system_host_keys()
            password = ""
            try:
                try:
                    self.ssh.connect(hostname, username=username)
                except paramiko.ssh_exception.AuthenticationException:
                    password = getpass.getpass(f"{self.address} password:")
                    self.ssh.connect(hostname, username=username, password=password)
            except (OSError, paramiko.ssh_exception.SSHException) as ex:
                raise BlueError(f"Failed connecting to {hostname}: {ex}") from None
            finally:
                del password
            self.sftp = self.ssh.open_sftp()

    def get_full_path(self, local_path: pathlib.Path | str) -> str:
        """Return full path including host address in remote mode."""
        return str(local_path) if self.ssh is None else f"{self.address}:{local_path}"

    def iterdir_attr(self, path: pathlib.Path) -> Iterator[paramiko.SFTPAttributes]:
        """Yield SFTPAttributes objects of the folder content."""
        if self.sftp is None:
            for subpath in path.iterdir():
                yield paramiko.SFTPAttributes.from_stat(subpath.stat(), subpath.name)
        else:
            yield from self.sftp.listdir_attr(str(path))

    def run(
        self, args: Sequence[str], *, force_local: bool = False
    ) -> subprocess.CompletedProcess[bytes]:
        """Run the command described by args and wait for it to complete."""
        if force_local or self.ssh is None:
            proc = subprocess.run(args, check=False, capture_output=True)
        else:
            command = " ".join(args)
            _ssh_stdin, ssh_stdout, ssh_stderr = self.ssh.exec_command(command)
            proc = subprocess.CompletedProcess(
                args=args,
                returncode=0,
                stdout=ssh_stdout.read(),
                stderr=ssh_stderr.read(),
            )
        return proc

    def open(self, filepath: pathlib.Path, mode: OpenBinaryMode) -> BinaryIO:
        """Open file locally or remotely."""
        if "b" not in mode:
            raise BlueError(f"File '{filepath}' must be opened in binary mode")
        try:
            if self.sftp is None:
                return filepath.open(mode=mode)
            sftp_file = self.sftp.file(str(filepath), mode)
            return cast(BinaryIO, sftp_file)
        except OSError as ex:
            raise BlueError(
                f"Failed opening '{self.get_full_path(filepath)}': {ex}"
            ) from ex


class FolderInfo(TypedDict, total=False):
    """Information in RHS of backup folder table."""

    target: str
    exclude: list[str]


@dataclasses.dataclass
class BackupFolder:
    """Configuration for one backup folder source and target."""

    source_address: str | None
    source_path: pathlib.Path
    target_path: pathlib.Path
    exclude: tuple[str, ...] = ()

    @classmethod
    def from_toml(
        cls, source_location: str, folder_info: FolderInfo | str | None = None
    ) -> BackupFolder:
        """Generate folder from data in the TOML file."""
        if ":" in source_location:
            source_address, source_folder = source_location.split(":", 2)
        else:
            source_address, source_folder = None, source_location
        source_path = pathlib.Path(source_folder)

        exclude: tuple[str, ...] = ()
        if folder_info is None:
            target_path = source_path.relative_to("/")
        elif isinstance(folder_info, str):  # folder_info is just target_path
            target_path = pathlib.Path(folder_info)
        else:  # folder_info is FolderInfo
            if "target" in folder_info:
                target_path = pathlib.Path(folder_info.pop("target"))
            else:
                target_path = source_path.relative_to("/")
            if "exclude" in folder_info:
                exclude = tuple(folder_info.pop("exclude"))
            for key in folder_info:
                Logger.WARNING.print(f"Unknown field for '{source_location}': '{key}'")
        return cls(source_address, source_path, target_path, exclude)

    def get_source_location(self) -> str:
        """Get source location formatted for the rsync command."""
        # str(path / "_")[:-1] is to ensure that path ends with a "/".
        source_folder_str = str(self.source_path / "_")[:-1]
        if self.source_address is None:
            return source_folder_str
        return f"{self.source_address}:{source_folder_str}"


@dataclasses.dataclass
class Config:
    """Configuration from the TOML file."""

    target_location: str
    backup_folders: tuple[BackupFolder, ...]
    exclude: tuple[str, ...] = ()

    @classmethod
    def from_toml(cls, filename: str) -> Config:
        """Create a Config class from a TOML file."""
        try:
            with pathlib.Path(filename).open(mode="rb") as toml_file:
                toml_dict = tomllib.load(toml_file)
        except (OSError, tomllib.TOMLDecodeError) as ex:
            raise BlueError(f"Failed to read '{filename}': {ex}") from ex

        try:
            target_location: str = toml_dict.pop("target-location")
            backup_folders: list[str] | dict[str, FolderInfo | str] = toml_dict.pop(
                "backup-folders"
            )
            exclude: list[str] = toml_dict.pop("exclude", [])
        except KeyError as ex:
            raise BlueError(f"Missing in '{filename}': {ex}") from ex
        for key in toml_dict:
            Logger.WARNING.print(f"Unknown field in '{filename}': '{key}'")

        if isinstance(backup_folders, list):
            backup_folders_conf = tuple(
                BackupFolder.from_toml(source_location)
                for source_location in backup_folders
            )
        elif isinstance(backup_folders, dict):
            backup_folders_conf = tuple(
                BackupFolder.from_toml(source_location, folder_info)
                for source_location, folder_info in backup_folders.items()
            )
        else:
            raise BlueError("'backup-folders' must be an array or a table.")

        config = cls(target_location, backup_folders_conf, tuple(exclude))
        toml_folder_path = pathlib.Path(filename).resolve().parent
        config.apply_var(TOML_FOLDER=str(toml_folder_path))
        return config

    def apply_var(self, **kwargs: str) -> None:
        """Apply variable replacement to all paths in configuration."""
        self.target_location = self.target_location.format(**kwargs)
        for bf in self.backup_folders:
            bf.source_path = pathlib.Path(str(bf.source_path).format(**kwargs))
            bf.target_path = pathlib.Path(str(bf.target_path).format(**kwargs))

    def get_address_and_path(self) -> tuple[str | None, pathlib.Path]:
        """Break target location to address and path."""
        target_address: str | None = None
        target_location = self.target_location
        if ":" in self.target_location:
            target_address, target_location = self.target_location.split(":", 2)
        target_path = pathlib.Path(target_location)
        return target_address, target_path


@dataclasses.dataclass
class BlueBackup:
    """Backup using rsync."""

    config: Config
    first_time: bool = False
    dry_run: bool = False
    checksum: bool = False

    def __post_init__(self) -> None:
        """Prepare for backup."""
        target_address, target_path = self.config.get_address_and_path()

        if not target_path.is_absolute():
            raise BlueError(f"Target location '{target_path}' must be absoluse path.")
        for bf in self.config.backup_folders:
            if not bf.source_path.is_absolute():
                raise BlueError(
                    f"Source location '{bf.source_path}' must be absoluse path."
                )

        self.proc = Process(target_address)
        self.folder_list: list[pathlib.Path] = []

        try:
            for path_attr in self.proc.iterdir_attr(target_path):
                if path_attr.st_mode is not None and stat.S_ISDIR(path_attr.st_mode):
                    folder_path = target_path / path_attr.filename
                    try:
                        date = datetime.date.fromisoformat(folder_path.name)
                        iso_date = date.isoformat()
                        if folder_path.name != iso_date:
                            raise ValueError(f"{folder_path.name} != {iso_date}")
                    except ValueError as ex:
                        Logger.WARNING.print(
                            f"Folder {folder_path.name}, non ISO date: {ex}"
                        )
                    else:
                        self.folder_list.append(folder_path)
        except OSError as ex:
            raise BlueError(
                f"Failed reading target location '{self.config.target_location}': {ex}"
            ) from ex

        today = datetime.date.today()
        self.today_folder = target_path / str(today)
        self.log_file = self.today_folder.with_suffix(".log")

    def _print_output(self, text: str, *, to_log_file: bool = True) -> None:
        Logger.OUTPUT.print(text)
        if to_log_file and not self.dry_run:
            with self.proc.open(self.log_file, mode="ab") as log_file:
                log_file.write(f"{text}\n".encode())

    def _print_command(self, text: str) -> None:
        Logger.COMMAND.print(text)
        if not self.dry_run:
            with self.proc.open(self.log_file, mode="ab") as log_file:
                log_file.write(f"\n{text}\n".encode())

    def _print_error(self, text: str) -> None:
        Logger.ERROR.print(text)
        if not self.dry_run:
            with self.proc.open(self.log_file, mode="ab") as log_file:
                log_file.write(f"{text}\n".encode())

    def _run(
        self,
        *args: str | pathlib.Path,
        filter_output: Callable[[bytes], None] | None = None,
        force_local: bool = False,
    ) -> int:
        """Run an external command in a subprocess."""
        if force_local or self.proc.ssh is None:
            str_args = ("/usr/bin/sudo", *(str(arg) for arg in args))
            self._print_command(" ".join(str_args))
        else:
            str_args = tuple(str(arg) for arg in args)
            self._print_command(f"""ssh {self.proc.address} {" ".join(str_args)}""")
        if self.dry_run:
            return 0

        proc = self.proc.run(str_args, force_local=force_local)
        if filter_output is None:
            if len(proc.stdout) > 0:
                self._print_output(proc.stdout.decode("utf8"))
        else:
            filter_output(proc.stdout)
        if len(proc.stderr) > 0:
            self._print_error(proc.stderr.decode("utf8"))
        if proc.returncode != 0:
            self._print_error(f"Return code: {proc.returncode}")

        return proc.returncode

    def _filter_rsync_output(self, output: bytes) -> None:
        """Filter the output of 'rsync --info=stats2'."""
        # The output should look something like:
        #
        # Number of files: 321,415 (reg: 277,623, dir: 43,413, link: 375, special: 4)
        # Number of created files: 54 (reg: 43, dir: 11)
        # Number of deleted files: 18 (reg: 14, dir: 4)
        # Number of regular files transferred: 239
        # Total file size: 177.91G bytes
        # Total transferred file size: 4.45G bytes
        # Literal data: 4.45G bytes
        # Matched data: 0 bytes
        # File list size: 851.87K
        # File list generation time: 0.001 seconds
        # File list transfer time: 0.000 seconds
        # Total bytes sent: 4.46G
        # Total bytes received: 51.68K
        #
        # sent 4.46G bytes  received 51.68K bytes  33.93M bytes/sec
        # total size is 177.91G  speedup is 39.87
        for line in output.decode("utf8").split("\n"):
            if line.startswith((
                "Total file size:",
                "Total transferred file size:",
            )):
                self._print_output(line, to_log_file=False)

    def backup(self) -> None:
        """Perform the actual backup."""
        new_day = self.today_folder not in self.folder_list

        if self.first_time:
            if len(self.folder_list) > 0:
                raise BlueError(
                    "This is not the first time you are backing up to this folder, "
                    "remove --first-time"
                )
            self._run("/usr/bin/mkdir", self.today_folder)

        elif new_day:
            # New day - new backup folder:
            if len(self.folder_list) == 0:
                raise BlueError(
                    "This is the first time you are backing up to this folder, "
                    "specify --first-time"
                )
            last_folder = max(self.folder_list)
            self._run("/usr/bin/cp", "-al", last_folder, self.today_folder)
            self.folder_list.append(self.today_folder)

        rsync_command = [
            "/usr/bin/rsync", "--archive", "--human-readable", "--info=stats2",
            # Create all missing path components of the destination path:
            "--mkpath",
        ]
        if self.proc.ssh is None:
            rsync_command.append(f"--log-file={self.log_file}")
        else:
            # Log to file on the remote (receiver) side:
            rsync_command.append(f"--remote-option=--log-file={self.log_file}")
        if self.checksum:
            rsync_command.append("--checksum")

        if new_day:
            # Start a new day with removing files that do not exist anymore:
            rsync_command.extend(["--delete", "--delete-excluded"])

        for backup_folder in self.config.backup_folders:
            # str(path / "_")[:-1] is to ensure that path ends with a "/".
            source_folder_str = backup_folder.get_source_location()
            backup_target_str = str(
                self.today_folder / backup_folder.target_path / "_"
            )[:-1]
            backup_target_str = self.proc.get_full_path(backup_target_str)
            self._run(
                *rsync_command,
                *(
                    f"--exclude={folder}"
                    for folder in self.config.exclude + backup_folder.exclude
                ),
                source_folder_str,
                backup_target_str,
                filter_output=self._filter_rsync_output,
                force_local=True,
            )

        # Commit filesystem caches to disk:
        self._run("/usr/bin/sync", self.today_folder)

    def purge(self, *, keep: int) -> None:
        """Purge old backups."""
        folder_list = sorted(self.folder_list)
        months = {folder.name[:7] for folder in self.folder_list}

        monthly_backups = 0
        for folder in folder_list.copy():
            if folder.name[:7] in months:
                monthly_backups += 1
                folder_list.pop(folder_list.index(folder))
                months.remove(folder.name[:7])
        self._print_output(f"Kept monthly backups: {monthly_backups}")

        while len(folder_list) > keep:
            self._run("/usr/bin/rm", "-r", folder_list[0])
            # self._run("/usr/bin/rm", folder_list[0].with_suffix(".log"))
            folder_list.pop(0)
        self._print_output(f"Kept daily backups: {len(folder_list)}")

    def disk_space(self) -> None:
        """Report available disk space in target location."""
        self._run("/usr/bin/df", "--human-readable", self.today_folder)

    @classmethod
    def from_command_line_arguments(cls) -> BlueBackup:
        """Initialize a Backup class instance from command line arguments."""
        parser = argparse.ArgumentParser()
        parser.add_argument("--config", default="blue-backup.toml")
        parser.add_argument("--first-time", action="store_true")
        parser.add_argument("--dry-run", action="store_true")
        parser.add_argument("--checksum", action="store_true")
        args = parser.parse_args()

        config = Config.from_toml(args.config)
        backup_args = vars(args)
        backup_args["config"] = config

        return cls(**backup_args)


def main() -> None:
    """Backup main entry-point."""
    try:
        backup = BlueBackup.from_command_line_arguments()
        backup.backup()
        backup.purge(keep=20)
        backup.disk_space()
    except BlueError as ex:
        Logger.ERROR.print(str(ex))
        raise SystemExit(1) from ex


if __name__ == "__main__":
    main()
