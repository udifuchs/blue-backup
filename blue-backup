#! /usr/bin/env python3
"""Backup using rsync."""

from __future__ import annotations

import argparse
import atexit
import contextlib
import dataclasses
import datetime
import enum
import getpass
import os
import pathlib
import stat
import subprocess
import sys
from collections.abc import Callable, Iterator
from typing import BinaryIO, Literal, Sequence, TypedDict, cast

if sys.version_info >= (3, 11):
    from typing import Self
else:  # Avoid depending on typing-extensions
    from typing import Any as Self

if sys.version_info >= (3, 10):
    from typing import TypeAlias

if sys.version_info >= (3, 11):
    import tomllib
else:
    import tomli as tomllib

import paramiko

if sys.version_info >= (3, 10):
    OpenBinaryMode: TypeAlias = Literal["rb", "wb", "ab"]
else:
    OpenBinaryMode = Literal["rb", "wb", "ab"]


class BlueError(Exception):
    """blue-backup failed."""


class ProcessError(BlueError):
    """Error while executing external process."""

    def __init__(self, error_message: str, return_code: int) -> None:
        super().__init__(f"{error_message}Return code: {return_code}")


class Logger(enum.Enum):
    """Log messages."""

    OUTPUT = "\033[32m"  # Green
    COMMAND = "\033[94m"  # Blue
    ERROR = "\033[91m"  # Red
    WARNING = "\033[33m"  # Yellow
    _RESET = "\033[0m"

    def print(self, text: str) -> None:
        """Print a log message."""
        stream = sys.stderr if self in {Logger.ERROR, Logger.WARNING} else sys.stdout
        if stream.isatty():
            stream.write(f"{self.value}{text}{Logger._RESET.value}\n")
        else:
            stream.write(f"{text}\n")
            # Flushing is needed when invoked using: ssh hostname ./blue-backup
            # To get a colored output, force pseudo-terminal allocation using: ssh -t
            stream.flush()


class AlreadyRunningError(BlueError):
    """A different process is currently holding this PID file."""


class PIDFile:
    """Context manager for PID files."""
    # Based on: https://github.com/mosquito/python-pidfile

    def __init__(self, filename: str) -> None:
        self._filepath = pathlib.Path(filename)

    @staticmethod
    def _get_cmdline(pid: int) -> list[str]:
        # Based on psutil/_pslinux.py
        cmdline_path = pathlib.Path(f"/proc/{pid}/cmdline")
        with cmdline_path.open("r", encoding="utf-8") as cmdline_file:
            cmdline = cmdline_file.read()
            if not cmdline:  # may happen in case of zombie process
                return []
            if cmdline.endswith("\x00"):
                cmdline = cmdline[:-1]
        return cmdline.split("\x00")

    @property
    def is_running(self) -> bool:
        """Check if PID file exists and if there is a process using it."""
        if not self._filepath.exists():
            return False

        with self._filepath.open(mode="r", encoding="utf-8") as pid_file:
            try:
                pid = int(pid_file.read())
            except (OSError, ValueError):
                return False

        # Check if pid currently exists:
        try:
            os.kill(pid, 0)
        except ProcessLookupError:
            return False
        except PermissionError:
            pass

        try:
            pid_cmdline = self._get_cmdline(pid)
            my_cmdline = self._get_cmdline(os.getpid())
        except PermissionError:
            return False
        # cmdline[0] should be "python3".
        # cmdline[1] should be the path to this python code.
        return pid_cmdline[0] == my_cmdline[0] and pid_cmdline[1] == my_cmdline[1]

    def close(self) -> None:
        """Remove PID file."""
        if self._filepath.exists():
            with contextlib.suppress(OSError):
                self._filepath.unlink()

    def __enter__(self) -> Self:
        """Try to create the PID file to enter the context manager."""
        if self.is_running:
            raise AlreadyRunningError(f"Process for {self._filepath} already running.")

        with self._filepath.open("w", encoding="utf-8") as pid_file:
            pid_file.write(str(os.getpid()))

        atexit.register(self.close)

        return self

    def __exit__(self, *_args: object) -> None:
        """Remove the PID file on exiting the context manager."""
        self.close()
        atexit.unregister(self.close)


class Process:
    """Handle local and remote processes and filesystem access.

    For local access, subprocess and pathlib modules are used.
    For remote access, paramiko's ssh and sftp are used.
    """

    def __init__(self, address: str | None) -> None:
        """Initialize process for remote or local host."""
        hostname: str | None
        if address is not None and "@" in address:
            username, hostname = address.split("@", 2)
        else:
            username, hostname = os.getlogin(), address
        self.address = address

        self.ssh = None
        self.sftp = None
        if hostname is not None:
            self.ssh = paramiko.SSHClient()
            self.ssh.load_system_host_keys()
            password = ""
            try:
                try:
                    self.ssh.connect(hostname, username=username)
                except paramiko.ssh_exception.AuthenticationException:
                    password = getpass.getpass(f"{self.address} password:")
                    self.ssh.connect(hostname, username=username, password=password)
            except (OSError, paramiko.ssh_exception.SSHException) as ex:
                raise BlueError(f"Failed connecting to {hostname}: {ex}") from None
            finally:
                del password
            self.sftp = self.ssh.open_sftp()

    def get_full_path(self, local_path: pathlib.Path | str) -> str:
        """Return full path including host address in remote mode."""
        return str(local_path) if self.ssh is None else f"{self.address}:{local_path}"

    def iterdir_attr(self, path: pathlib.Path) -> Iterator[paramiko.SFTPAttributes]:
        """Yield SFTPAttributes objects of the folder content."""
        if self.sftp is None:
            for subpath in path.iterdir():
                yield paramiko.SFTPAttributes.from_stat(subpath.stat(), subpath.name)
        else:
            yield from self.sftp.listdir_attr(str(path))

    def run(
        self, args: Sequence[str], *, force_local: bool = False
    ) -> subprocess.CompletedProcess[bytes]:
        """Run the command described by args and wait for it to complete."""
        if force_local or self.ssh is None:
            proc = subprocess.run(args, check=False, capture_output=True)
        else:
            command = " ".join(args)
            _ssh_stdin, ssh_stdout, ssh_stderr = self.ssh.exec_command(command)
            proc = subprocess.CompletedProcess(
                args=args,
                returncode=0,
                stdout=ssh_stdout.read(),
                stderr=ssh_stderr.read(),
            )
        return proc

    def open(self, filepath: pathlib.Path, mode: OpenBinaryMode) -> BinaryIO:
        """Open file locally or remotely."""
        if "b" not in mode:
            raise BlueError(f"File '{filepath}' must be opened in binary mode")
        try:
            if self.sftp is None:
                return filepath.open(mode=mode)
            sftp_file = self.sftp.file(str(filepath), mode)
            return cast(BinaryIO, sftp_file)
        except OSError as ex:
            raise BlueError(
                f"Failed opening '{self.get_full_path(filepath)}': {ex}"
            ) from ex


class FolderInfo(TypedDict, total=False):
    """Information in RHS of backup folder table."""

    target: str
    exclude: list[str]


@dataclasses.dataclass
class BackupFolder:
    """Configuration for one backup folder source and target."""

    source_address: str | None
    source_path: pathlib.Path
    target_path: pathlib.Path
    exclude: tuple[str, ...] = ()

    @classmethod
    def from_toml(cls, source_location: str, folder_info: FolderInfo) -> Self:
        """Generate folder from data in the TOML file."""
        if ":" in source_location:
            source_address, source_folder = source_location.split(":", 2)
        else:
            source_address, source_folder = None, source_location
        source_path = pathlib.Path(source_folder)

        if not isinstance(folder_info, dict):
            raise BlueError(f"Folder info for '{source_location}' must be a table.")
        if "target" in folder_info:
            target_path = pathlib.Path(folder_info.pop("target"))
        else:
            target_path = source_path.relative_to("/")
        exclude = tuple(folder_info.pop("exclude")) if "exclude" in folder_info else ()
        for key in folder_info:
            Logger.WARNING.print(f"Unknown field for '{source_location}': '{key}'")
        return cls(source_address, source_path, target_path, exclude)

    def get_source_location(self) -> str:
        """Get source location formatted for the rsync command."""
        # str(path / "_")[:-1] is to ensure that path ends with a "/".
        source_folder_str = str(self.source_path / "_")[:-1]
        if self.source_address is None:
            return source_folder_str
        return f"{self.source_address}:{source_folder_str}"


@dataclasses.dataclass
class Config:
    """Configuration from the TOML file."""

    target_address: str | None
    target_path: pathlib.Path
    backup_folders: tuple[BackupFolder, ...]
    exclude: tuple[str, ...] = ()

    @classmethod
    def from_toml(cls, filename: str) -> Self:
        """Create a Config class from a TOML file."""
        try:
            with pathlib.Path(filename).open(mode="rb") as toml_file:
                toml_dict = tomllib.load(toml_file)
        except (OSError, tomllib.TOMLDecodeError) as ex:
            raise BlueError(f"Failed to read '{filename}': {ex}") from ex

        try:
            target_location: str = toml_dict.pop("target-location")
            backup_folders: dict[str, FolderInfo] = toml_dict.pop("backup-folders")
            exclude: list[str] = toml_dict.pop("exclude", [])
        except KeyError as ex:
            raise BlueError(f"Missing in '{filename}': {ex}") from ex
        for key in toml_dict:
            Logger.WARNING.print(f"Unknown field in '{filename}': '{key}'")

        # Break target location to address and path.
        target_address: str | None = None
        if ":" in target_location:
            target_address, target_location = target_location.split(":", 2)
        target_path = pathlib.Path(target_location)

        if isinstance(backup_folders, dict):
            backup_folders_conf = tuple(
                BackupFolder.from_toml(source_location, folder_info)
                for source_location, folder_info in backup_folders.items()
            )
        else:
            raise BlueError("'backup-folders' must be a table.")

        config = cls(target_address, target_path, backup_folders_conf, tuple(exclude))
        toml_folder_path = pathlib.Path(filename).resolve().parent
        config.apply_var(TOML_FOLDER=str(toml_folder_path))
        return config

    def apply_var(self, **kwargs: str) -> None:
        """Apply variable replacement to all paths in configuration."""
        self.target_path = pathlib.Path(str(self.target_path).format(**kwargs))
        for bf in self.backup_folders:
            bf.source_path = pathlib.Path(str(bf.source_path).format(**kwargs))
            bf.target_path = pathlib.Path(str(bf.target_path).format(**kwargs))

    def check_all_paths_absolute(self) -> None:
        """Make sure that all paths in configuration are absolute."""
        if not self.target_path.is_absolute():
            raise BlueError(
                f"Target location '{self.target_path}' must be absolute path."
            )
        for bf in self.backup_folders:
            if not bf.source_path.is_absolute():
                raise BlueError(
                    f"Source location '{bf.source_path}' must be absolute path."
                )

    def get_target_location(self) -> str:
        """Get target location."""
        if self.target_address is None:
            return str(self.target_path)
        return f"{self.target_address}:{self.target_path}"


@dataclasses.dataclass
class BlueBackup:
    """Backup using rsync."""

    config: Config
    toml_config: str
    first_time: bool = False
    dry_run: bool = False
    checksum: bool = False
    print_summary: bool = False

    def __post_init__(self) -> None:
        """Prepare for backup."""
        self.config.check_all_paths_absolute()
        self.proc = Process(self.config.target_address)
        self.folder_list: list[pathlib.Path] = []

        try:
            for path_attr in self.proc.iterdir_attr(self.config.target_path):
                if path_attr.st_mode is not None and stat.S_ISDIR(path_attr.st_mode):
                    folder_path = self.config.target_path / path_attr.filename
                    try:
                        date = datetime.date.fromisoformat(folder_path.name)
                        iso_date = date.isoformat()
                        if folder_path.name != iso_date:
                            raise ValueError(f"{folder_path.name} != {iso_date}")
                    except ValueError as ex:
                        Logger.WARNING.print(
                            f"Folder {folder_path.name}, non ISO date: {ex}"
                        )
                    else:
                        self.folder_list.append(folder_path)
        except OSError as ex:
            raise BlueError(
                f"Failed reading target location "
                f"'{self.config.get_target_location()}': {ex}"
            ) from ex

        today = datetime.date.today()
        self.today_folder = self.config.target_path / str(today)
        self.log_file = self.today_folder.with_suffix(".log")
        self._print_output(f"Backup: {self.config.get_target_location()} {today}")
        self.target_is_btrfs: bool

        def check_stat_output(output: bytes) -> None:
            """Callback for checking target file system type."""
            str_out = output.decode("utf8").strip()  # Remove any newlines.
            self.target_is_btrfs = str_out == "btrfs"

        self._run(
            "/usr/bin/stat", "--file-system", "--format=%T", self.config.target_path,
            filter_output=check_stat_output,
        )

    def _print_output(self, text: str, *, to_log_file: bool = True) -> None:
        Logger.OUTPUT.print(text)
        if to_log_file and not self.dry_run:
            with self.proc.open(self.log_file, mode="ab") as log_file:
                log_file.write(f"{text}\n".encode())

    def _print_command(self, text: str) -> None:
        if not self.print_summary:
            # Do not print commands in summary mode.
            Logger.COMMAND.print(text)
        if not self.dry_run:
            with self.proc.open(self.log_file, mode="ab") as log_file:
                log_file.write(f"\n{text}\n".encode())

    def _print_error(self, text: str) -> None:
        Logger.ERROR.print(text)
        if not self.dry_run:
            with self.proc.open(self.log_file, mode="ab") as log_file:
                log_file.write(f"{text}\n".encode())

    def _run(
        self,
        *args: str | pathlib.Path,
        filter_output: Callable[[bytes], None] | None = None,
        force_local: bool = False,
    ) -> None:
        """Run an external command in a subprocess."""
        str_args = tuple(str(arg) for arg in args)
        if force_local or self.proc.ssh is None:
            self._print_command(" ".join(str_args))
        else:
            self._print_command(f"""ssh {self.proc.address} {" ".join(str_args)}""")
        if self.dry_run:
            return

        proc = self.proc.run(str_args, force_local=force_local)
        if filter_output is None:
            if len(proc.stdout) > 0:
                # The [:-1] is to remove the last newline.
                self._print_output(proc.stdout.decode("utf8")[:-1])
        else:
            filter_output(proc.stdout)
        if len(proc.stderr) > 0 or proc.returncode != 0:
            raise ProcessError(proc.stderr.decode("utf8"), proc.returncode)

    def _filter_rsync_output(self, output: bytes) -> None:
        """Filter the output of 'rsync --info=stats2'."""
        # The output should look something like:
        #
        # Number of files: 321,415 (reg: 277,623, dir: 43,413, link: 375, special: 4)
        # Number of created files: 54 (reg: 43, dir: 11)
        # Number of deleted files: 18 (reg: 14, dir: 4)
        # Number of regular files transferred: 239
        # Total file size: 177.91G bytes
        # Total transferred file size: 4.45G bytes
        # Literal data: 4.45G bytes
        # Matched data: 0 bytes
        # File list size: 851.87K
        # File list generation time: 0.001 seconds
        # File list transfer time: 0.000 seconds
        # Total bytes sent: 4.46G
        # Total bytes received: 51.68K
        #
        # sent 4.46G bytes  received 51.68K bytes  33.93M bytes/sec
        # total size is 177.91G  speedup is 39.87
        out_lines = [
            line for line in output.decode("utf8").split("\n")
            if line.startswith((
                "Total file size:",
                "Total transferred file size:",
            ))
        ]
        self._print_output(" / ".join(out_lines), to_log_file=False)

    def create_new_backup_folder(self) -> None:
        """Prepare a new folder for today's backup."""
        if len(self.folder_list) == 0:
            raise BlueError(
                "This is the first time you are backing up to this folder, "
                "specify --first-time"
            )
        last_folder = max(self.folder_list)
        if self.target_is_btrfs:
            # When using btrfs snapshots, first set last snapshot to readonly:
            self._run(
                "/usr/bin/btrfs", "property", "set", "-ts", last_folder, "ro", "true"
            )
            self._run(
                "/usr/bin/btrfs", "subvolume", "snapshot",
                last_folder, self.today_folder
            )
        else:
            # Create snapshot using hard links.
            self._run("/usr/bin/cp", "-al", last_folder, self.today_folder)
        self.folder_list.append(self.today_folder)

    def backup(self) -> None:
        """Perform the actual backup."""
        new_day = self.today_folder not in self.folder_list

        if self.first_time:
            if len(self.folder_list) > 0:
                raise BlueError(
                    "This is not the first time you are backing up to this folder, "
                    "remove --first-time"
                )
            if self.target_is_btrfs:
                self._run("/usr/bin/btrfs", "subvolume", "create", self.today_folder)
            else:
                self._run("/usr/bin/mkdir", self.today_folder)

        elif new_day:
            # New day - new backup folder:
            self.create_new_backup_folder()

        rsync_command = [
            "/usr/bin/rsync", "--archive", "--human-readable", "--info=stats2",
            # Remove files that do not exist anymore:
            "--delete", "--delete-excluded",
            # Create all missing path components of the destination path:
            "--mkpath",
        ]
        if self.proc.ssh is None:
            rsync_command.append(f"--log-file={self.log_file}")
        else:
            # Log to file on the remote (receiver) side:
            rsync_command.append(f"--remote-option=--log-file={self.log_file}")
        if self.checksum:
            rsync_command.append("--checksum")

        for backup_folder in self.config.backup_folders:
            if self.print_summary:
                # Full rsync command is not printed. Print short summary instead:
                self._print_output(
                    f"rsync {backup_folder.get_source_location()}", to_log_file=False
                )
            # str(path / "_")[:-1] is to ensure that path ends with a "/".
            source_folder_str = backup_folder.get_source_location()
            backup_target_str = str(
                self.today_folder / backup_folder.target_path / "_"
            )[:-1]
            backup_target_str = self.proc.get_full_path(backup_target_str)
            try:
                self._run(
                    *rsync_command,
                    *(
                        f"--exclude={folder}"
                        for folder in self.config.exclude + backup_folder.exclude
                    ),
                    source_folder_str,
                    backup_target_str,
                    filter_output=self._filter_rsync_output,
                    force_local=True,
                )
            except ProcessError as ex:
                self._print_error(str(ex))

        # Commit filesystem caches to disk:
        self._run("/usr/bin/sync", self.today_folder)

    def purge(self, *, keep: int) -> None:
        """Purge old backups."""
        folder_list = sorted(self.folder_list)
        months = {folder.name[:7] for folder in self.folder_list}

        monthly_backups = 0
        for folder in folder_list.copy():
            if folder.name[:7] in months:
                monthly_backups += 1
                folder_list.pop(folder_list.index(folder))
                months.remove(folder.name[:7])
        self._print_output(f"Kept monthly backups: {monthly_backups}")

        while len(folder_list) > keep:
            try:
                if self.target_is_btrfs:
                    self._run("/usr/bin/btrfs", "subvolume", "delete", folder_list[0])
                else:
                    self._run("/usr/bin/rm", "-r", folder_list[0])
                # self._run("/usr/bin/rm", folder_list[0].with_suffix(".log"))
            except ProcessError as ex:
                self._print_error(str(ex))
            folder_list.pop(0)
        self._print_output(f"Kept daily backups: {len(folder_list)}")

    def disk_space(self) -> None:
        """Report available disk space in target location."""
        self._run("/usr/bin/df", "--human-readable", self.today_folder)

    @classmethod
    def from_command_line_arguments(cls) -> Self:
        """Initialize a Backup class instance from command line arguments."""
        parser = argparse.ArgumentParser()
        parser.add_argument("toml_config", nargs="?", default="blue-backup.toml")
        parser.add_argument("--first-time", action="store_true")
        parser.add_argument("--dry-run", action="store_true")
        parser.add_argument("--checksum", action="store_true")
        parser.add_argument("--print-summary", action="store_true")
        args = parser.parse_args()

        config = Config.from_toml(args.toml_config)
        backup_args = vars(args)

        return cls(config=config, **backup_args)


def main() -> None:
    """Backup main entry-point."""
    try:
        backup = BlueBackup.from_command_line_arguments()
        with PIDFile(backup.toml_config + ".pid"):
            backup.backup()
            backup.purge(keep=20)
            backup.disk_space()
    except BlueError as ex:
        Logger.ERROR.print(str(ex))
        raise SystemExit(1) from ex


if __name__ == "__main__":
    main()
